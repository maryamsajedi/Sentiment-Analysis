{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"y9uAlw2eAj0S","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1695637940926,"user_tz":-120,"elapsed":17888,"user":{"displayName":"Maryam Sajedinia","userId":"11320540451160711396"}},"outputId":"ed1bdb5f-b228-48a5-8bcf-7b477c1e2a66"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["!pip install torchtext==0.6 --quiet"],"metadata":{"id":"auJxwRPTUdj0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1695637956493,"user_tz":-120,"elapsed":6295,"user":{"displayName":"Maryam Sajedinia","userId":"11320540451160711396"}},"outputId":"8e3da687-8a72-4761-fae9-f60123f89742"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["!pip install pyprind"],"metadata":{"id":"yeDEBG_i0RUq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1695637962337,"user_tz":-120,"elapsed":4712,"user":{"displayName":"Maryam Sajedinia","userId":"11320540451160711396"}},"outputId":"a960bee8-faff-4378-db1d-bdfe7808b73c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pyprind\n","  Downloading PyPrind-2.11.3-py2.py3-none-any.whl (8.4 kB)\n","Installing collected packages: pyprind\n","Successfully installed pyprind-2.11.3\n"]}]},{"cell_type":"code","source":["import torch\n","from torchtext import data\n","import torch.nn as nn\n","import torch.optim as optim\n","from sklearn.metrics import precision_score, recall_score, f1_score\n","import csv\n","import pandas as pd\n","import pyprind\n","import time\n","import json\n"],"metadata":{"id":"OanqGQiysrwc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["SEED = 1234\n","\n","torch.manual_seed(SEED)\n","torch.backends.cudnn.deterministic = True\n","\n","TEXT = data.Field(tokenize = 'spacy',\n","                  tokenizer_language = 'en_core_web_sm')\n","LABEL = data.LabelField(dtype = torch.float)\n","\n","fields = [('text', TEXT), ('label', LABEL)]\n","\n","train_data, valid_data, test_data = data.TabularDataset.splits(\n","                                        path = '/content/drive/MyDrive/Sentiment-Analysis/Data/wo. Neutral Splits',\n","                                        train = 'TrainFile.csv',\n","                                        validation = 'DevFile.csv',\n","                                        test = 'TestFile.csv',\n","                                        format = 'csv',\n","                                        fields = fields,\n","                                        skip_header = False\n",")\n"],"metadata":{"id":"TIzhoSvIVIhW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# test_data.examples.pop(0)\n"],"metadata":{"id":"mjYE__8agKud"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["MAX_VOCAB_SIZE = 25_000\n","\n","TEXT.build_vocab(train_data, max_size = MAX_VOCAB_SIZE)\n","LABEL.build_vocab(train_data)\n","\n","print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")\n","print(f\"Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}\")\n"],"metadata":{"id":"pnPkt4-BXEbS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1695637996712,"user_tz":-120,"elapsed":434,"user":{"displayName":"Maryam Sajedinia","userId":"11320540451160711396"}},"outputId":"a060d0fc-7603-4c73-c541-64327ec42e02"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Unique tokens in TEXT vocabulary: 25002\n","Unique tokens in LABEL vocabulary: 2\n"]}]},{"cell_type":"code","source":["BATCH_SIZE = 16\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n","    (train_data, valid_data, test_data),\n","    batch_size = BATCH_SIZE,\n","    device = device,\n","    sort=False)"],"metadata":{"id":"BmI4t-QDadku"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class RNN(nn.Module):\n","    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim, dropout):\n","        super().__init__()\n","        self.hidden_dim = hidden_dim\n","        self.embedding = nn.Embedding(input_dim, embedding_dim)\n","        self.rnn = nn.RNN(embedding_dim, hidden_dim, dropout=dropout)\n","        self.fc = nn.Linear(hidden_dim, output_dim)\n","\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x):\n","\n","        embedded = self.dropout(self.embedding(x))\n","\n","        output, hidden = self.rnn(embedded)\n","\n","        assert torch.equal(output[-1,:,:], hidden.squeeze(0))\n","\n","        hidden = self.dropout(hidden)\n","\n","        out = self.fc(hidden)\n","        return out"],"metadata":{"id":"iWTN_ZgGbnBk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["INPUT_DIM = len(TEXT.vocab)\n","EMBEDDING_DIM = 100\n","HIDDEN_DIM = 128\n","OUTPUT_DIM = 1\n","DROPOUT = 0.5\n","model =  RNN(INPUT_DIM,\n","            EMBEDDING_DIM,\n","            HIDDEN_DIM,\n","            OUTPUT_DIM,\n","            DROPOUT)\n"],"metadata":{"id":"W1Yngps5bpGG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1695638033544,"user_tz":-120,"elapsed":269,"user":{"displayName":"Maryam Sajedinia","userId":"11320540451160711396"}},"outputId":"2df54bf3-7f54-4bcf-d4e2-0d6a6d4982fa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]}]},{"cell_type":"code","source":["def count_parameters(model):\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","print(f'The model has {count_parameters(model):,} trainable parameters')"],"metadata":{"id":"PBZ5JxiPbsPX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1695638035794,"user_tz":-120,"elapsed":260,"user":{"displayName":"Maryam Sajedinia","userId":"11320540451160711396"}},"outputId":"0062a357-3577-4fbb-990d-211315d6250c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The model has 2,529,769 trainable parameters\n"]}]},{"cell_type":"code","source":["optimizer = optim.Adam(model.parameters(), lr=0.00003)"],"metadata":{"id":"wdeG5PlIb0Q8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["criterion = nn.BCEWithLogitsLoss()\n","model = model.to(device)\n","criterion = criterion.to(device)\n"],"metadata":{"id":"pPEFAYqjb4k2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def accuracy(preds, y):\n","    rounded_preds = torch.round(torch.sigmoid(preds))\n","    correct = (rounded_preds == y).float() #convert into float for division\n","    acc = correct.sum() / len(rounded_preds)\n","    return acc"],"metadata":{"id":"InZi4UJxb-FD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def precision(preds, labels):\n","    rounded_preds = torch.round(torch.sigmoid(torch.tensor(preds)))\n","    precision = precision_score(torch.tensor(labels), rounded_preds, average='macro')\n","    return precision"],"metadata":{"id":"uOZ3u9oXA0yU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def recall(preds, labels):\n","    rounded_preds = torch.round(torch.sigmoid(torch.tensor(preds)))\n","    recall = recall_score(torch.tensor(labels), rounded_preds,average='macro')\n","    return recall"],"metadata":{"id":"rqc1fJpwBSSU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def f1(preds, labels):\n","    rounded_preds = torch.round(torch.sigmoid(torch.tensor(preds)))\n","    f1 = f1_score(torch.tensor(labels), rounded_preds,average='macro')\n","    return f1"],"metadata":{"id":"qRQsZp_NB1j5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def test_evaluate(model, iterator, criterion):\n","\n","    epoch_loss = 0\n","    epoch_acc = 0\n","    all_predictions = []\n","    all_labels = []\n","    all_text=[]\n","    df = pd.DataFrame(columns=[\"RNN-label\"])\n","    model.eval()\n","\n","    with torch.no_grad():\n","\n","        for batch in iterator:\n","            predictions = model(batch.text.to(device)).squeeze()\n","            loss = criterion(predictions, batch.label)\n","            acc = accuracy(predictions, batch.label)\n","\n","            all_predictions.extend(predictions)\n","            all_labels.extend(batch.label)\n","\n","            epoch_loss += loss.item()\n","            epoch_acc += acc.item()\n","\n","        rounded_preds = torch.round(torch.sigmoid(torch.tensor(all_predictions)))\n","\n","        with open(\"/content/drive/MyDrive/Sentiment-Analysis/Data/evaluation.json\", 'r') as json_file:\n","          df = json.load(json_file)\n","\n","        for i, key in enumerate(df.keys()):\n","          df[key]['Rnn'] = int(rounded_preds[i])\n","\n","        with open(\"/content/drive/MyDrive/Sentiment-Analysis/Data/evaluation.json\", \"w\") as json_file:\n","          json.dump(df, json_file)\n","\n","        total_precision = precision(all_predictions, all_labels)\n","        total_recall = recall(all_predictions, all_labels)\n","        total_f1 = f1(all_predictions, all_labels)\n","\n","    return (epoch_loss / len(iterator),\n","            epoch_acc / len(iterator),\n","            total_precision,\n","            total_recall,\n","            total_f1)"],"metadata":{"id":"9E4GUjz_rLhS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train(model, iterator, optimizer, criterion):\n","\n","    epoch_loss = 0\n","    epoch_acc = 0\n","\n","    model.train()\n","    bar = pyprind.ProgBar(len(iterator), bar_char='█')\n","    for batch in iterator:\n","\n","        optimizer.zero_grad()\n","\n","        predictions = model(batch.text).squeeze()\n","\n","        loss = criterion(predictions, batch.label)\n","\n","        acc = accuracy(predictions, batch.label)\n","\n","        loss.backward()\n","\n","        optimizer.step()\n","\n","        epoch_loss += loss.item()\n","        epoch_acc += acc.item()\n","        bar.update()\n","\n","    return epoch_loss / len(iterator), epoch_acc / len(iterator)"],"metadata":{"id":"YCZlkcc3cBaE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def evaluate(model, iterator, criterion):\n","\n","    epoch_loss = 0\n","    epoch_acc = 0\n","\n","    model.eval()\n","\n","    with torch.no_grad():\n","        bar = pyprind.ProgBar(len(iterator), bar_char='█')\n","        for batch in iterator:\n","\n","            predictions = model(batch.text).squeeze()\n","\n","            loss = criterion(predictions, batch.label)\n","\n","            acc = accuracy(predictions, batch.label)\n","\n","            epoch_loss += loss.item()\n","            epoch_acc += acc.item()\n","            bar.update()\n","\n","    return epoch_loss / len(iterator), epoch_acc / len(iterator)"],"metadata":{"id":"_CXHdYPlcEqx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def epoch_time(start_time, end_time):\n","    elapsed_time = end_time - start_time\n","    elapsed_mins = int(elapsed_time / 60)\n","    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n","    return elapsed_mins, elapsed_secs"],"metadata":{"id":"oylZ4YINcJja"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["N_EPOCHS = 10\n","\n","best_valid_loss = float('inf')\n","\n","for epoch in range(N_EPOCHS):\n","\n","    start_time = time.time()\n","\n","    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n","    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n","\n","    end_time = time.time()\n","\n","    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n","\n","    if valid_loss < best_valid_loss:\n","        best_valid_loss = valid_loss\n","        torch.save(model.state_dict(), 'tut1-model.pt')\n","\n","\n","    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n","    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n","    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"],"metadata":{"id":"zJzmEZAecNBH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.load_state_dict(torch.load('/content/drive/MyDrive/Sentiment-Analysis/models/RNN-model.pt'))\n","test_loss, test_acc, test_prec, test_recall, test_f1 = test_evaluate(model, test_iterator, criterion)\n","\n","print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}% | Test Prec: {test_prec}%| Test recall: {test_recall:.3f}% |Test f1: {test_f1:.3f}')"],"metadata":{"id":"Lde3wlMKwwOq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1695638083986,"user_tz":-120,"elapsed":4977,"user":{"displayName":"Maryam Sajedinia","userId":"11320540451160711396"}},"outputId":"b58937e1-fda9-4331-fa53-f1c307353a8c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Test Loss: 0.266 | Test Acc: 88.98% | Test Prec: 0.7491679656001959%| Test recall: 0.843% |Test f1: 0.784\n"]}]},{"cell_type":"code","source":["def merger(model, iterator, criterion):\n","\n","    epoch_loss = 0\n","    epoch_acc = 0\n","    all_predictions = []\n","    all_labels = []\n","    all_text=[]\n","    df = pd.DataFrame(columns=[\"RNN-label\"])\n","    model.eval()\n","\n","    with torch.no_grad():\n","\n","        for batch in iterator:\n","            predictions = model(batch.text.to(device)).squeeze()\n","            loss = criterion(predictions, batch.label)\n","            acc = accuracy(predictions, batch.label)\n","\n","            all_predictions.extend(predictions)\n","            all_labels.extend(batch.label)\n","\n","    readablepred = torch.round(torch.sigmoid(torch.tensor(all_predictions))).tolist()\n","    actual_labels = [tensor.item() for tensor in all_labels]\n","    correct = sum(1 for pred, actual in zip(readablepred, actual_labels) if pred == actual)\n","    all = len(readablepred)\n","    accuracy = correct / all\n","    print(actual_labels)\n","    return readablepred\n","\n","\n","a=merger(model, test_iterator, criterion)\n","b=merger(model, test_iterator, criterion)\n","c=merger(model, test_iterator, criterion)\n","d=merger(model, test_iterator, criterion)\n","e=merger(model, test_iterator, criterion)\n"],"metadata":{"id":"qnHrT5_cQ0NC"},"execution_count":null,"outputs":[]}]}