{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip install torchtext==0.6"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"auJxwRPTUdj0","executionInfo":{"status":"ok","timestamp":1695638772925,"user_tz":-120,"elapsed":5983,"user":{"displayName":"Maryam Sajedinia","userId":"11320540451160711396"}},"outputId":"dd778aec-b9be-474d-f501-bb49dd7423aa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting torchtext==0.6\n","  Downloading torchtext-0.6.0-py3-none-any.whl (64 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6) (4.66.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6) (2.31.0)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6) (2.0.1+cu118)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6) (1.23.5)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6) (1.16.0)\n","Collecting sentencepiece (from torchtext==0.6)\n","  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6) (2023.7.22)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6) (3.12.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->torchtext==0.6) (3.27.4.1)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->torchtext==0.6) (16.0.6)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->torchtext==0.6) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->torchtext==0.6) (1.3.0)\n","Installing collected packages: sentencepiece, torchtext\n","  Attempting uninstall: torchtext\n","    Found existing installation: torchtext 0.15.2\n","    Uninstalling torchtext-0.15.2:\n","      Successfully uninstalled torchtext-0.15.2\n","Successfully installed sentencepiece-0.1.99 torchtext-0.6.0\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2hHz9b8g5uBo","executionInfo":{"status":"ok","timestamp":1695638799046,"user_tz":-120,"elapsed":24056,"user":{"displayName":"Maryam Sajedinia","userId":"11320540451160711396"}},"outputId":"694a64e3-d62b-459c-b663-2989e771ce2c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import time\n","import json\n","import torch\n","import torch.optim as optim\n","\n","from torchtext.data.field import LabelField\n","from torchtext import data\n","from tqdm import tqdm\n","from sklearn.metrics import precision_score, recall_score, f1_score"],"metadata":{"id":"ST4AShfE1pTH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["SEED = 1234\n","\n","torch.manual_seed(SEED)\n","torch.backends.cudnn.deterministic = True\n","\n","TEXT = data.Field(tokenize = 'spacy',\n","                  tokenizer_language = 'en_core_web_sm',\n","                  include_lengths = True)\n","\n","LABEL = data.LabelField(dtype = torch.float)"],"metadata":{"id":"TIzhoSvIVIhW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fields = [('text', TEXT), ('label', LABEL)]\n","\n","train_data, valid_data, test_data = data.TabularDataset.splits(\n","                                        path = '/content/drive/MyDrive/Sentiment-Analysis/Data/wo. Neutral Splits',\n","                                        train = 'TrainFile.csv',\n","                                        validation = 'DevFile.csv',\n","                                        test = 'long-review-test.csv',\n","                                        format = 'csv',\n","                                        fields = fields,\n","                                        skip_header = False\n",")"],"metadata":{"id":"t18iMY8k6NI5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# test_data.examples.pop(0)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K1GrXeekR49m","executionInfo":{"status":"ok","timestamp":1695639513750,"user_tz":-120,"elapsed":600,"user":{"displayName":"Maryam Sajedinia","userId":"11320540451160711396"}},"outputId":"d937efd0-92a9-4b5d-bd55-1b8dcf08e90d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torchtext.data.example.Example at 0x7f595c93c640>"]},"metadata":{},"execution_count":39}]},{"cell_type":"code","source":["MAX_VOCAB_SIZE = 25_000\n","\n","TEXT.build_vocab(train_data,\n","                 max_size = MAX_VOCAB_SIZE,\n","                 vectors = \"glove.6B.100d\",\n","                 unk_init = torch.Tensor.normal_)\n","\n","LABEL.build_vocab(train_data)\n"],"metadata":{"id":"pnPkt4-BXEbS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["BATCH_SIZE = 64\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n","    (train_data, valid_data, test_data),\n","    batch_size = BATCH_SIZE,\n","    sort_within_batch = False,\n","    sort=False,\n","    device = device,\n","    )"],"metadata":{"id":"BmI4t-QDadku"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch.nn as nn\n","\n","class GRUModel(nn.Module):\n","    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers,\n","                 bidirectional, dropout, pad_idx):\n","\n","        super().__init__()\n","\n","        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)\n","\n","        self.rnn = nn.GRU(embedding_dim,\n","                          hidden_dim,\n","                          num_layers=n_layers,\n","                          bidirectional=bidirectional,\n","                          dropout=dropout)\n","\n","        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n","\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, text, text_lengths):\n","\n","        embedded = self.dropout(self.embedding(text))\n","\n","        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths.to('cpu'), enforce_sorted=False)\n","\n","        packed_output, hidden = self.rnn(packed_embedded)\n","\n","        output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output)\n","\n","        hidden = self.dropout(torch.cat((hidden[-2, :, :], hidden[-1, :, :]), dim=1))\n","\n","        return self.fc(hidden)"],"metadata":{"id":"iWTN_ZgGbnBk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["INPUT_DIM = len(TEXT.vocab)\n","EMBEDDING_DIM = 100\n","HIDDEN_DIM = 256\n","OUTPUT_DIM = 1\n","N_LAYERS = 2\n","BIDIRECTIONAL = True\n","DROPOUT = 0.5\n","PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n","\n","model = GRUModel(INPUT_DIM,\n","            EMBEDDING_DIM,\n","            HIDDEN_DIM,\n","            OUTPUT_DIM,\n","            N_LAYERS,\n","            BIDIRECTIONAL,\n","            DROPOUT,\n","            PAD_IDX)"],"metadata":{"id":"W1Yngps5bpGG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def count_parameters(model):\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","print(f'The model has {count_parameters(model):,} trainable parameters')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PBZ5JxiPbsPX","executionInfo":{"status":"ok","timestamp":1695639522933,"user_tz":-120,"elapsed":3,"user":{"displayName":"Maryam Sajedinia","userId":"11320540451160711396"}},"outputId":"2cf33739-3bb3-477f-9f3f-e620a652d19b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The model has 4,233,321 trainable parameters\n"]}]},{"cell_type":"code","source":["pretrained_embeddings = TEXT.vocab.vectors\n","\n","print(pretrained_embeddings.shape)\n","\n","model.embedding.weight.data.copy_(pretrained_embeddings)"],"metadata":{"id":"9daHONiwk1pc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1695639524367,"user_tz":-120,"elapsed":10,"user":{"displayName":"Maryam Sajedinia","userId":"11320540451160711396"}},"outputId":"6f2a913a-1db9-4a0f-c45a-d340d8a800f5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([25002, 100])\n"]},{"output_type":"execute_result","data":{"text/plain":["tensor([[ 1.6506,  0.0865,  1.3287,  ...,  0.5458,  0.8515,  0.1580],\n","        [-0.8772,  2.1614,  0.7010,  ...,  0.1617, -0.4898,  0.3106],\n","        [-0.0308,  0.1199,  0.5391,  ..., -0.5288,  0.1758,  1.0650],\n","        ...,\n","        [-0.9083,  0.1065, -0.5070,  ...,  0.1728, -1.0311,  1.2032],\n","        [ 1.8723,  0.1652, -0.3859,  ..., -0.8991, -0.3518,  0.8838],\n","        [-1.6545, -0.3179, -1.1832,  ..., -0.0497, -0.8147, -2.2842]])"]},"metadata":{},"execution_count":45}]},{"cell_type":"code","source":["UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n","\n","model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n","model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n","\n","print(model.embedding.weight.data)"],"metadata":{"id":"wdeG5PlIb0Q8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1695639525373,"user_tz":-120,"elapsed":8,"user":{"displayName":"Maryam Sajedinia","userId":"11320540451160711396"}},"outputId":"d07c0096-5971-4f83-c4d5-49fe8564d4f0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","        [-0.0308,  0.1199,  0.5391,  ..., -0.5288,  0.1758,  1.0650],\n","        ...,\n","        [-0.9083,  0.1065, -0.5070,  ...,  0.1728, -1.0311,  1.2032],\n","        [ 1.8723,  0.1652, -0.3859,  ..., -0.8991, -0.3518,  0.8838],\n","        [-1.6545, -0.3179, -1.1832,  ..., -0.0497, -0.8147, -2.2842]])\n"]}]},{"cell_type":"code","source":["optimizer = optim.Adam(model.parameters())"],"metadata":{"id":"9G_rqW2Jk8gu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["criterion = nn.BCEWithLogitsLoss()\n","model = model.to(device)\n","criterion = criterion.to(device)"],"metadata":{"id":"pPEFAYqjb4k2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def accuracy(preds, y):\n","    \"\"\"\n","    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n","    \"\"\"\n","\n","    #round predictions to the closest integer\n","    rounded_preds = torch.round(torch.sigmoid(preds))\n","    correct = (rounded_preds == y).float() #convert into float for division\n","    acc = correct.sum() / len(correct)\n","    return acc"],"metadata":{"id":"InZi4UJxb-FD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train(model, iterator, optimizer, criterion):\n","\n","    epoch_loss = 0\n","    epoch_acc = 0\n","\n","    model.train()\n","\n","    for batch in tqdm(iterator):\n","\n","        optimizer.zero_grad()\n","\n","        text, text_lengths = batch.text\n","\n","        predictions = model(text, text_lengths).squeeze(1)\n","\n","        loss = criterion(predictions, batch.label.float())  # Convert label to float for binary cross-entropy\n","\n","        acc = accuracy(predictions, batch.label)\n","\n","        loss.backward()\n","\n","        optimizer.step()\n","\n","        epoch_loss += loss.item()\n","        epoch_acc += acc.item()\n","\n","    return epoch_loss / len(iterator), epoch_acc / len(iterator)"],"metadata":{"id":"YCZlkcc3cBaE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def evaluate(model, iterator, criterion):\n","\n","    epoch_loss = 0\n","    epoch_acc = 0\n","\n","    model.eval()\n","\n","    with torch.no_grad():\n","\n","        for batch in iterator:\n","\n","            text, text_lengths = batch.text\n","\n","            predictions = model(text, text_lengths).squeeze(1)\n","\n","            loss = criterion(predictions, batch.label)\n","\n","            acc = accuracy(predictions, batch.label)\n","\n","            epoch_loss += loss.item()\n","            epoch_acc += acc.item()\n","\n","    return epoch_loss / len(iterator), epoch_acc / len(iterator)"],"metadata":{"id":"_CXHdYPlcEqx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def epoch_time(start_time, end_time):\n","    elapsed_time = end_time - start_time\n","    elapsed_mins = int(elapsed_time / 60)\n","    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n","    return elapsed_mins, elapsed_secs"],"metadata":{"id":"oylZ4YINcJja"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["N_EPOCHS = 10\n","from tqdm import tqdm\n","\n","best_valid_loss = float('inf')\n","\n","for epoch in range(N_EPOCHS):\n","\n","    start_time = time.time()\n","\n","    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n","    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n","\n","    end_time = time.time()\n","\n","    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n","\n","    if valid_loss < best_valid_loss:\n","        best_valid_loss = valid_loss\n","        torch.save(model.state_dict(), 'tut2-model.pt')\n","\n","    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n","    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n","    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"],"metadata":{"id":"zJzmEZAecNBH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1694969714451,"user_tz":-120,"elapsed":415193,"user":{"displayName":"maryam sajedinia","userId":"14910188422885344998"}},"outputId":"ec3ba5ee-825f-47d7-e3e8-22c1b52b429a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 2431/2431 [00:41<00:00, 58.92it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 01 | Epoch Time: 0m 42s\n","\tTrain Loss: 0.083 | Train Acc: 97.04%\n","\t Val. Loss: 0.050 |  Val. Acc: 98.13%\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 2431/2431 [00:40<00:00, 60.58it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 02 | Epoch Time: 0m 41s\n","\tTrain Loss: 0.054 | Train Acc: 98.01%\n","\t Val. Loss: 0.055 |  Val. Acc: 98.02%\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 2431/2431 [00:40<00:00, 60.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 03 | Epoch Time: 0m 41s\n","\tTrain Loss: 0.046 | Train Acc: 98.27%\n","\t Val. Loss: 0.048 |  Val. Acc: 98.21%\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 2431/2431 [00:40<00:00, 60.66it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 04 | Epoch Time: 0m 41s\n","\tTrain Loss: 0.041 | Train Acc: 98.45%\n","\t Val. Loss: 0.049 |  Val. Acc: 98.27%\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 2431/2431 [00:40<00:00, 60.65it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 05 | Epoch Time: 0m 41s\n","\tTrain Loss: 0.038 | Train Acc: 98.58%\n","\t Val. Loss: 0.044 |  Val. Acc: 98.47%\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 2431/2431 [00:40<00:00, 60.73it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 06 | Epoch Time: 0m 41s\n","\tTrain Loss: 0.034 | Train Acc: 98.70%\n","\t Val. Loss: 0.046 |  Val. Acc: 98.50%\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 2431/2431 [00:40<00:00, 60.65it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 07 | Epoch Time: 0m 41s\n","\tTrain Loss: 0.032 | Train Acc: 98.78%\n","\t Val. Loss: 0.046 |  Val. Acc: 98.33%\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 2431/2431 [00:40<00:00, 59.93it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 08 | Epoch Time: 0m 41s\n","\tTrain Loss: 0.030 | Train Acc: 98.86%\n","\t Val. Loss: 0.046 |  Val. Acc: 98.44%\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 2431/2431 [00:40<00:00, 60.25it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 09 | Epoch Time: 0m 41s\n","\tTrain Loss: 0.028 | Train Acc: 98.95%\n","\t Val. Loss: 0.047 |  Val. Acc: 98.47%\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 2431/2431 [00:40<00:00, 60.14it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 10 | Epoch Time: 0m 42s\n","\tTrain Loss: 0.027 | Train Acc: 99.01%\n","\t Val. Loss: 0.049 |  Val. Acc: 98.40%\n"]}]},{"cell_type":"code","source":["def precision(preds, labels):\n","    rounded_preds = torch.round(torch.sigmoid(torch.tensor(preds)))\n","    precision = precision_score(torch.tensor(labels), rounded_preds, average='weighted')\n","    return precision\n","\n","\n","def recall(preds, labels):\n","    rounded_preds = torch.round(torch.sigmoid(torch.tensor(preds)))\n","    recall = recall_score(torch.tensor(labels), rounded_preds, average='weighted')\n","    return recall\n","\n","\n","def f1(preds, labels):\n","    rounded_preds = torch.round(torch.sigmoid(torch.tensor(preds)))\n","    f1 = f1_score(torch.tensor(labels), rounded_preds, average='weighted')\n","    return f1\n","\n","def test_evaluate(model, iterator, criterion):\n","\n","    epoch_loss = 0\n","    epoch_acc = 0\n","    all_predictions = []\n","    all_labels = []\n","\n","    model.eval()\n","\n","    with torch.no_grad():\n","\n","        for batch in iterator:\n","\n","            text, text_lengths = batch.text\n","\n","            predictions = model(text, text_lengths).squeeze(1)\n","            loss = criterion(predictions, batch.label)\n","            acc = accuracy(predictions, batch.label)\n","\n","            all_predictions.extend(predictions)\n","            all_labels.extend(batch.label)\n","\n","\n","            epoch_loss += loss.item()\n","            epoch_acc += acc.item()\n","\n","        rounded_preds = torch.round(torch.sigmoid(torch.tensor(all_predictions)))\n","\n","        with open(\"/content/drive/MyDrive/Sentiment-Analysis/Data/evaluation.json\", 'r') as json_file:\n","          df = json.load(json_file)\n","\n","        for i, key in enumerate(df.keys()):\n","          df[key]['GRU'] = int(rounded_preds[i])\n","\n","        with open(\"/content/drive/MyDrive/Sentiment-Analysis/Data/evaluation.json\", \"w\") as json_file:\n","          json.dump(df, json_file)\n","\n","        total_precision = precision(all_predictions, all_labels)\n","        total_recall = recall(all_predictions, all_labels)\n","        total_f1 = f1(all_predictions, all_labels)\n","\n","    return (epoch_loss / len(iterator),\n","            epoch_acc / len(iterator),\n","            total_precision,\n","            total_recall,\n","            total_f1)"],"metadata":{"id":"386EpyTBcPlv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.load_state_dict(torch.load('/content/drive/MyDrive/Sentiment-Analysis/models/GRU-model.pt'))\n","\n","test_loss, test_acc , prec, recall, f1= test_evaluate(model, test_iterator, criterion)\n","\n","print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%', prec, recall, f1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r7LHMgOJcZCu","executionInfo":{"status":"ok","timestamp":1695639548516,"user_tz":-120,"elapsed":469,"user":{"displayName":"Maryam Sajedinia","userId":"11320540451160711396"}},"outputId":"91968f46-eaf0-4788-8801-e4feaf08c407"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Test Loss: 0.251 | Test Acc: 91.08% 0.9072645328851882 0.9056603773584906 0.9064086096596791\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"8PQXUhlkH3eu"},"execution_count":null,"outputs":[]}]}